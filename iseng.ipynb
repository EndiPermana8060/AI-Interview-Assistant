{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_groq\n",
      "  Using cached langchain_groq-0.2.4-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from langchain_groq) (0.18.0)\n",
      "Collecting langchain-core<0.4.0,>=0.3.33 (from langchain_groq)\n",
      "  Using cached langchain_core-0.3.36-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-core<0.4.0,>=0.3.33->langchain_groq)\n",
      "  Using cached langsmith-0.3.8-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<0.4.0,>=0.3.33->langchain_groq)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.33->langchain_groq)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core<0.4.0,>=0.3.33->langchain_groq)\n",
      "  Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (24.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain_groq)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq)\n",
      "  Using cached orjson-3.10.15-cp39-cp39-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests<3,>=2 (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq)\n",
      "  Using cached zstandard-0.23.0-cp39-cp39-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.27.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq)\n",
      "  Using cached charset_normalizer-3.4.1-cp39-cp39-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Using cached langchain_groq-0.2.4-py3-none-any.whl (14 kB)\n",
      "Using cached langchain_core-0.3.36-py3-none-any.whl (413 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.3.8-py3-none-any.whl (332 kB)\n",
      "Using cached PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached orjson-3.10.15-cp39-cp39-win_amd64.whl (133 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached zstandard-0.23.0-cp39-cp39-win_amd64.whl (495 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp39-cp39-win_amd64.whl (102 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: zstandard, urllib3, tenacity, PyYAML, orjson, jsonpointer, charset-normalizer, requests, jsonpatch, requests-toolbelt, langsmith, langchain-core, langchain_groq\n",
      "Successfully installed PyYAML-6.0.2 charset-normalizer-3.4.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.36 langchain_groq-0.2.4 langsmith-0.3.8 orjson-3.10.15 requests-2.32.3 requests-toolbelt-1.0.0 tenacity-9.0.0 urllib3-2.3.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv('GROQ_API_KEY')\n",
    "class ChatBot:\n",
    "    def __init__(self):\n",
    "        # Initialize the ChatGroq model using the provided API key and a specific model.\n",
    "        \n",
    "        self.llm = ChatGroq(groq_api_key=GROQ_API_KEY, model_name=\"llama-3.3-70b-versatile\")\n",
    "        \n",
    "        # Define the prompt template for generating suggestions.\n",
    "        self.gen_suggestion_template = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"You are a helpful assistant that receives text input in Indonesian and designed to support interviewers. Given the conversation text provided, generate up to 3 insightful follow-up questions using indonesian language. These questions should help the interviewer explore the candidate's experience, problem-solving abilities, or other relevant areas more deeply. Ensure the questions are relevant, concise, and written in Indonesian to suit the context.\"\n",
    "                ),\n",
    "                (\n",
    "                    \"human\",\n",
    "                    \"Input:\\n{text}\\nPlease analyze this conversation and generate follow-up questions based on the interview flow.\"\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Create a suggestion generation chain by combining the template and the model.\n",
    "        self.generate_suggestion_chain = self.gen_suggestion_template | self.llm\n",
    "\n",
    "    def generate_suggestion(self, text):\n",
    "        # Invoke the suggestion generation chain with the provided text and return the response.\n",
    "        response = self.generate_suggestion_chain.invoke({'text':text}).content\n",
    "        return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Utils\n",
    "from chatbot import ChatBot\n",
    "utility = Utils()\n",
    "bot = ChatBot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"hasil_transkripsi.txt\"  # Ensure correct path format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file content\n",
    "content = utility.read_txt_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interviewer: \"Bagaimana Anda menangani masalah overfitting?\"\n",
      "\n",
      "Candidate: \"Untuk mengurangi overfitting, beberapa metode yang umum digunakan adalah regularisasi, pengurangan kompleksitas model, dan penggunaan teknik seperti cross-validation untuk memastikan model tidak terlalu sesuai dengan data pelatihan.\"\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate suggestions using the bot's generate_suggestion method\n",
    "response = bot.generate_suggestion(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berikut beberapa pertanyaan lanjutan yang dapat membantu interviewer untuk lebih memahami pengalaman dan kemampuan candidate:\n",
      "\n",
      "1. \"Apakah Anda pernah mengalami kasus di mana regularisasi dan pengurangan kompleksitas model tidak cukup efektif untuk mengatasi overfitting? Jika ya, bagaimana Anda menanganinya?\"\n",
      "2. \"Bagaimana Anda memilih jenis regularisasi yang tepat (misalnya L1 atau L2) untuk mengatasi overfitting dalam suatu model? Apakah ada pertimbangan khusus yang Anda gunakan?\"\n",
      "3. \"Dalam penggunaan cross-validation, bagaimana Anda menentukan jumlah fold yang optimal untuk menghindari overfitting dan underfitting? Apakah ada aturan umum yang Anda ikuti dalam menentukan jumlah fold?\"\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
